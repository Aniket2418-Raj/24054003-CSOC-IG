{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12019304,"sourceType":"datasetVersion","datasetId":7561921}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-01T07:04:48.128994Z","iopub.execute_input":"2025-06-01T07:04:48.129566Z","iopub.status.idle":"2025-06-01T07:04:48.149074Z","shell.execute_reply.started":"2025-06-01T07:04:48.129532Z","shell.execute_reply":"2025-06-01T07:04:48.148076Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/housing/housing.csv\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import r2_score\nimport time\n\n# Step 1: Load CSV using pandas\ndef load_csv_pandas(filepath):\n    if not os.path.isfile(filepath):\n        raise FileNotFoundError(f\"File not found: {filepath}\")\n    df = pd.read_csv(filepath)\n\n    print(\"Columns in dataset:\", df.columns.tolist())\n    print(\"Initial data info:\")\n    print(df.info())\n    print(\"First 5 rows:\")\n    print(df.head())\n\n    # Drop rows with missing values\n    df = df.dropna()\n    print(f\"Data shape after dropping missing values: {df.shape}\")\n\n    return df\n\n# Step 2: Prepare features and labels, handle categorical encoding\ndef prepare_data(df):\n    target_col = 'median_house_value'\n    \n    if target_col not in df.columns:\n        raise ValueError(f\"Target column '{target_col}' not found\")\n\n    y = pd.to_numeric(df[target_col], errors='coerce')\n    X = df.drop(columns=[target_col])\n\n    mask = ~y.isna()\n    y = y[mask]\n    X = X.loc[mask]\n\n    X = pd.get_dummies(X, drop_first=True)\n\n    print(f\"Feature columns after encoding: {X.columns.tolist()}\")\n    print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n\n    return X.values.tolist(), y.values.tolist()  # for pure python, convert to list\n\n# Step 3: Scale features\ndef scale_features(X_train, X_val):\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_val_scaled = scaler.transform(X_val)\n    return X_train_scaled.tolist(), X_val_scaled.tolist()  # convert back to list\n\n# Step 4: Pure Python Linear Regression Model\nclass LinearRegressionPurePython:\n    def __init__(self, lr=0.01, n_iters=500):\n        self.lr = lr\n        self.n_iters = n_iters\n        self.weights = []\n        self.bias = 0\n\n    def fit(self, X, y):\n        start = time.time()\n        n_samples, n_features = len(X), len(X[0])\n        self.weights = [0.0] * n_features\n        self.bias = 0\n\n        for _ in range(self.n_iters):\n            y_pred = [self._predict(x) for x in X]\n            dw = [0.0] * n_features\n            db = 0.0\n\n            for i in range(n_samples):\n                error = y_pred[i] - y[i]\n                for j in range(n_features):\n                    dw[j] += error * X[i][j]\n                db += error\n\n            for j in range(n_features):\n                self.weights[j] -= self.lr * dw[j] / n_samples\n            self.bias -= self.lr * db / n_samples\n\n        end = time.time()\n        return end - start\n\n    def _predict(self, x):\n        return sum(w * xi for w, xi in zip(self.weights, x)) + self.bias\n\n    def predict(self, X):\n        return [self._predict(x) for x in X]\n\n# Step 5: MAE and MSE calculation\ndef calculate_mae_mse_python(y_true, y_pred):\n    n = len(y_true)\n    mae = sum(abs(y_t - y_p) for y_t, y_p in zip(y_true, y_pred)) / n\n    mse = sum((y_t - y_p) ** 2 for y_t, y_p in zip(y_true, y_pred)) / n\n    return mae, mse\n\n# Step 6: Run pipeline\nif __name__ == \"__main__\":\n    filename = '/kaggle/input/housing/housing.csv'  # Change this path if needed\n\n    df = load_csv_pandas(filename)\n    X, y = prepare_data(df)\n\n    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n    print(f\"Train samples: {len(X_train)}, Validation samples: {len(X_val)}\")\n\n    X_train_scaled, X_val_scaled = scale_features(X_train, X_val)\n\n    model = LinearRegressionPurePython(lr=0.01, n_iters=500)\n    duration = model.fit(X_train_scaled, y_train)\n\n    y_pred = model.predict(X_val_scaled)\n    r2 = r2_score(y_val, y_pred)\n    mae, mse = calculate_mae_mse_python(y_val, y_pred)\n\n    print(f\"\\n=== Evaluation Results ===\")\n    print(f\"Training Time: {duration:.4f} seconds\")\n    print(f\"R² Score: {r2:.4f}\")\n    print(f\"MAE (Pure Python): {mae:.4f}\")\n    print(f\"MSE (Pure Python): {mse:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T07:09:34.866159Z","iopub.execute_input":"2025-06-01T07:09:34.866541Z","iopub.status.idle":"2025-06-01T07:09:54.998396Z","shell.execute_reply.started":"2025-06-01T07:09:34.866508Z","shell.execute_reply":"2025-06-01T07:09:54.997627Z"}},"outputs":[{"name":"stdout","text":"Columns in dataset: ['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income', 'median_house_value', 'ocean_proximity']\nInitial data info:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 20640 entries, 0 to 20639\nData columns (total 10 columns):\n #   Column              Non-Null Count  Dtype  \n---  ------              --------------  -----  \n 0   longitude           20640 non-null  float64\n 1   latitude            20640 non-null  float64\n 2   housing_median_age  20640 non-null  float64\n 3   total_rooms         20640 non-null  float64\n 4   total_bedrooms      20433 non-null  float64\n 5   population          20640 non-null  float64\n 6   households          20640 non-null  float64\n 7   median_income       20640 non-null  float64\n 8   median_house_value  20640 non-null  float64\n 9   ocean_proximity     20640 non-null  object \ndtypes: float64(9), object(1)\nmemory usage: 1.6+ MB\nNone\nFirst 5 rows:\n   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n0    -122.23     37.88                41.0        880.0           129.0   \n1    -122.22     37.86                21.0       7099.0          1106.0   \n2    -122.24     37.85                52.0       1467.0           190.0   \n3    -122.25     37.85                52.0       1274.0           235.0   \n4    -122.25     37.85                52.0       1627.0           280.0   \n\n   population  households  median_income  median_house_value ocean_proximity  \n0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n4       565.0       259.0         3.8462            342200.0        NEAR BAY  \nData shape after dropping missing values: (20433, 10)\nFeature columns after encoding: ['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income', 'ocean_proximity_INLAND', 'ocean_proximity_ISLAND', 'ocean_proximity_NEAR BAY', 'ocean_proximity_NEAR OCEAN']\nX shape: (20433, 12), y shape: (20433,)\nTrain samples: 16346, Validation samples: 4087\n\n=== Evaluation Results ===\nTraining Time: 19.5795 seconds\nR² Score: 0.6278\nMAE (Pure Python): 51404.0466\nMSE (Pure Python): 5089531844.1236\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport time\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import r2_score\n\n# ----------------------------------------\n# Load and Clean CSV Data\ndef load_and_clean_csv(filepath):\n    df = pd.read_csv(filepath)\n\n    # Drop non-numeric columns like 'ocean_proximity'\n    df = df.select_dtypes(include=[np.number])\n\n    # Drop rows with missing values\n    df = df.dropna()\n\n    # Convert to NumPy array\n    return df.values\n\n# ----------------------------------------\n# Custom Linear Regression (NumPy)\nclass LinearRegressionNumpy:\n    def __init__(self, lr=0.01, n_iters=1000):  # FIXED\n        self.lr = lr\n        self.n_iters = n_iters\n        self.weights = None\n        self.bias = None\n\n    def fit(self, X, y):\n        start = time.time()\n        n_samples, n_features = X.shape\n        self.weights = np.zeros(n_features)\n        self.bias = 0\n\n        for _ in range(self.n_iters):\n            y_pred = np.dot(X, self.weights) + self.bias\n            error = y_pred - y\n\n            dw = (1 / n_samples) * np.dot(X.T, error)\n            db = (1 / n_samples) * np.sum(error)\n\n            self.weights -= self.lr * dw\n            self.bias -= self.lr * db\n\n        end = time.time()\n        return end - start\n\n    def predict(self, X):\n        return np.dot(X, self.weights) + self.bias\n\n# ----------------------------------------\n# MAE and MSE Evaluation using NumPy\ndef calculate_mae_mse_numpy(y_true, y_pred):\n    mae = np.mean(np.abs(y_true - y_pred))\n    mse = np.mean((y_true - y_pred) ** 2)\n    return mae, mse\n\n# ----------------------------------------\n# Main Execution\nif __name__ == \"__main__\":  # FIXED\n    filepath = \"/kaggle/input/housing/housing.csv\"\n\n    # Load and clean the dataset\n    data = load_and_clean_csv(filepath)\n\n    # Split into features and target\n    X = data[:, :-1]\n    y = data[:, -1]\n\n    # Train-validation split\n    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n    # Feature scaling\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_val_scaled = scaler.transform(X_val)\n\n    # Model training\n    model = LinearRegressionNumpy(lr=0.01, n_iters=500)\n    training_time = model.fit(X_train_scaled, y_train)\n\n    # Prediction and evaluation\n    y_pred = model.predict(X_val_scaled)\n    r2 = r2_score(y_val, y_pred)\n    mae, mse = calculate_mae_mse_numpy(y_val, y_pred)\n\n    # Final output\n    print(\"\\n=== Evaluation Results (NumPy Linear Regression) ===\")\n    print(f\"Training Time: {training_time:.4f} seconds\")\n    print(f\"R² Score: {r2:.4f}\")\n    print(f\"MAE: {mae:.4f}\")\n    print(f\"MSE: {mse:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T07:16:34.565127Z","iopub.execute_input":"2025-06-01T07:16:34.565538Z","iopub.status.idle":"2025-06-01T07:16:34.721050Z","shell.execute_reply.started":"2025-06-01T07:16:34.565499Z","shell.execute_reply":"2025-06-01T07:16:34.720057Z"}},"outputs":[{"name":"stdout","text":"\n=== Evaluation Results (NumPy Linear Regression) ===\nTraining Time: 0.0629 seconds\nR² Score: 0.5870\nMAE: 55162.3358\nMSE: 5647828380.1286\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport time\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# Load and preprocess data\ndef load_and_prepare_data(filepath):\n    df = pd.read_csv(filepath)\n\n    # Drop non-numeric column\n    if 'ocean_proximity' in df.columns:\n        df = df.drop(columns=['ocean_proximity'])\n\n    # Drop missing values\n    df = df.dropna()\n\n    # Split features and target\n    X = df.iloc[:, :-1].values\n    y = df.iloc[:, -1].values\n    return X, y\n\n# Main execution\nif __name__ == \"__main__\":\n    filepath = '/kaggle/input/housing/housing.csv'  # Ensure this path is correct\n\n    X, y = load_and_prepare_data(filepath)\n\n    # Train/val split\n    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n    # Feature scaling\n    scaler = StandardScaler()\n    X_train = scaler.fit_transform(X_train)\n    X_val = scaler.transform(X_val)\n\n    # Train model\n    model = LinearRegression()\n    start = time.time()\n    model.fit(X_train, y_train)\n    end = time.time()\n\n    # Predict and evaluate\n    preds = model.predict(X_val)\n    print(f\"Sklearn R²: {r2_score(y_val, preds):.4f}\")\n    print(f\"MAE: {mean_absolute_error(y_val, preds):.4f}\")\n    print(f\"MSE: {mean_squared_error(y_val, preds):.4f}\")\n    print(f\"Fit Time: {end - start:.4f} seconds\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T07:04:48.247093Z","iopub.execute_input":"2025-06-01T07:04:48.247506Z","iopub.status.idle":"2025-06-01T07:04:48.659417Z","shell.execute_reply.started":"2025-06-01T07:04:48.247475Z","shell.execute_reply":"2025-06-01T07:04:48.658359Z"}},"outputs":[{"name":"stdout","text":"Sklearn R²: 0.6401\nMAE: 51372.6722\nMSE: 4921881237.6281\nFit Time: 0.0802 seconds\n","output_type":"stream"}],"execution_count":5}]}